{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD learning of XOR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rand\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from lib.mu_w_2_20 import mu_mean\n",
    "from lib.lif import LIF, ParamsLIF, LIF_3layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import pandas as pd\n",
    "\n",
    "from lib.mu_w_2_20 import mu_mean\n",
    "from lib.lif import LIF, ParamsLIF, LIF_3layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_dim = 3               #Dimension of learnt vector\n",
    "dt = 0.001                 #Simulation timestep\n",
    "tsim = 500                 #Total simulation time\n",
    "DeltaT = 100               #Number of timebins over which learning rule is applied\n",
    "Tsim = DeltaT*dt           #Block sim time\n",
    "T = int((tsim/dt)/DeltaT)  #Total number of learning blocks\n",
    "tinput = 1                 #Time for input to be held fixed\n",
    "Tinput = int(tinput/Tsim)  #Number of blocks for input to be held fixed\n",
    "c = 0.01                   #Correlation coefficient\n",
    "n = 10                     #Number of neurons\n",
    "q = 1                      #Number of output neurons\n",
    "sigma = 10                 #Their noise level\n",
    "mu = 1                     #Spiking threshold\n",
    "tau = 1                    #Neuron timescale\n",
    "eta = 1e-1                 #Cost gradient learning rate (RDD)\n",
    "epsilon = 5e4              #Weight learning rate (RDD)\n",
    "p = .5                     #Learning window\n",
    "tau_s = 0.20               #Output filter timescale\n",
    "\n",
    "alpha = 200                #Cost of spiking when shouldn't\n",
    "beta = -300                #Reward for spiking when should\n",
    "wmax = 20                  #Max weight for hidden layer\n",
    "wmin = 2                   #Min weight for hidden layer\n",
    "umax = 20                  #Max weight for output layer\n",
    "umin = 2                   #Min weight for output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_filter = np.linspace(0, 1, 2000)\n",
    "exp_filter = np.exp(-t_filter/tau_s)\n",
    "exp_filter = exp_filter/np.sum(exp_filter)\n",
    "ds = exp_filter[0]\n",
    "\n",
    "params = ParamsLIF(n = n, tau = tau, sigma = sigma, c = c)\n",
    "lif = LIF_3layer(params, tau_s = tau_s, t = Tsim, t_total = tsim, alpha = 50)\n",
    "\n",
    "def xor(x):\n",
    "    return x[0] != x[1]\n",
    "\n",
    "def convolve_online(s, h, kernel, t_offset):\n",
    "    for idx in np.nonzero(h)[0]:\n",
    "        st = t_offset + idx\n",
    "        en = min(s.shape[0], st + kernel.shape[0])\n",
    "        ln = en-st\n",
    "        #print st,en,ln,idx,t_offset\n",
    "        s[st:en] += kernel[0:ln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup neurons\n",
    "Vo = np.zeros((1, beta_dim))\n",
    "Vh = np.zeros((n, beta_dim))\n",
    "dVo = np.zeros(Vo.shape)\n",
    "dVh = np.zeros(Vh.shape)\n",
    "\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "nI = len(inputs)\n",
    "\n",
    "#mean_cost = np.zeros(T)\n",
    "#mean_output = np.zeros(T)\n",
    "\n",
    "Whist = np.zeros((lif.W.shape[0], lif.W.shape[1], T))\n",
    "Uhist = np.zeros((lif.U.shape[0], lif.U.shape[1], T))\n",
    "Vohist = np.zeros((Vo.shape[0], Vo.shape[1], T))\n",
    "Vhhist = np.zeros((Vh.shape[0], Vh.shape[1], T))\n",
    "\n",
    "x_inputs_idx = np.zeros(T)\n",
    "\n",
    "bt_o = False\n",
    "bt_h = [False]*n\n",
    "\n",
    "s_rdd = np.zeros(int(tsim/dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning with RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This is the total time\n",
    "for j in range(T):\n",
    "    #Choose input at random for TI bins (say, a second's worth of simulation)\n",
    "    #x_input = np.random.rand(2)<0.5\n",
    "\n",
    "    #if x_input[0] == 0:\n",
    "    #    if x_input[1] == 0:\n",
    "    #        x_inputs_idx[idx] = 0\n",
    "    #    else:\n",
    "    #        x_inputs_idx[idx] = 1\n",
    "    #else:\n",
    "    #    if x_input[1] == 0:\n",
    "    #        x_inputs_idx[idx] = 2\n",
    "    #    else:\n",
    "    #        x_inputs_idx[idx] = 3\n",
    "\n",
    "    #Cycle through inputs\n",
    "    x_input = np.array(inputs[(j/Tinput)%4])\n",
    "    \n",
    "    #Simulate LIF for RDD\n",
    "    print(\"t = %d\"%j)\n",
    "    (vh_full, hh, vo_full, ho, uh_full, uo_full) = lif.simulate(x_input)\n",
    "        \n",
    "    #Compute cost function\n",
    "    t_offset = j*DeltaT\n",
    "    convolve_online(s_rdd, ho, exp_filter, t_offset)\n",
    "    dcost = alpha if xor(x_input) else beta\n",
    "    cost = dcost*s_rdd[t_offset+DeltaT]\n",
    "    #cost = dcost*np.mean(s_rdd[t_offset:t_offset+DeltaT])\n",
    "        \n",
    "    um = uh_full.reshape((n, 1, DeltaT))\n",
    "    uh = np.max(um, 2)    \n",
    "    um = uo_full.reshape((q, 1, DeltaT))\n",
    "    uo = np.max(um, 2)\n",
    "\n",
    "    #Update the hidden layer\n",
    "    for k in range(n):\n",
    "        if (uh[k,0] > mu - p) & (uh[k,0] < mu):\n",
    "            if bt_h[k] == False:\n",
    "                ahat = np.array([1, 0, 0])\n",
    "                dVh[k,:] += (np.dot(Vh[k,:], ahat)+cost)*ahat\n",
    "                bt_h[k] = True\n",
    "        elif (uh[k,0] < mu + p) & (uh[k,0] >= mu):\n",
    "            #Only do the update when firing...\n",
    "            if bt_h[k] == True:\n",
    "                ahat = np.array([1, 0, 0])\n",
    "                dVh[k,:] += (np.dot(Vh[k,:], ahat)-cost)*ahat\n",
    "                Vh[k,:] -= eta*dVh[k,:]\n",
    "                dVh[k,:] = np.zeros((1,beta_dim))\n",
    "                bt_h[k] = False\n",
    "\n",
    "        #Update weights according to W for RDD\n",
    "        #                             #######################################\n",
    "        #Need to know the relation between mean input, sigma, and firing rate\n",
    "        #lif.W[k,:] += epsilon*Vh[k,0]*mu_mean_xor_hidden(lif.W[k,:], x_input)\n",
    "        lif.W[k,:] = np.maximum(np.minimum(lif.W[k,:], wmax), wmin)\n",
    "        Whist[k,:,j] = lif.W[k,:]\n",
    "            \n",
    "    #Update the output layer\n",
    "    if (uo[0,0] > mu - p) & (uo[0,0] < mu):\n",
    "        if bt_o == False:\n",
    "            #ahat = np.array([1, 0, -(u[k,0]-mu)])\n",
    "            ahat = np.array([1, 0, 0])\n",
    "            dVo[0,:] += (np.dot(Vo[0,:], ahat)+cost)*ahat\n",
    "            bt_o = True\n",
    "    elif (uo[0,0] < mu + p) & (uo[0,0] >= mu):\n",
    "        #Only do the update when firing...\n",
    "        if bt_o == True:\n",
    "            #ahat = np.array([1, -(u[k,0]-mu), 0])\n",
    "            ahat = np.array([1, 0, 0])\n",
    "            dVo[0,:] += (np.dot(Vo[0,:], ahat)-cost)*ahat\n",
    "            Vo[0,:] -= eta*dVo[0,:]\n",
    "            dVo[0,:] = np.zeros((1,beta_dim))\n",
    "            bt_o = False\n",
    "    \n",
    "    #Update weights according to U for RDD\n",
    "    #                        #########################################\n",
    "    #lif.U += epsilon*Vo[0,0]*mu_mean_xor_output(lif.U, lif.W, x_input)\n",
    "    lif.U = np.maximum(np.minimum(lif.U, umax), umin)\n",
    "    Uhist[:,:,j] = lif.U\n",
    "    Vohist[:,:,j] = Vo\n",
    "    Vhhist[:,:,j] = Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
